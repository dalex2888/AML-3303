{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c02151",
   "metadata": {},
   "source": [
    "# **Modeling with MLflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b15d4",
   "metadata": {},
   "source": [
    "This notebook trains and compares multiple regression models to predict Airbnb listing prices using the V2 preprocessed dataset. All experiments are tracked using MLflow to enable systematic comparison and model selection.\n",
    "\n",
    "The preprocessed V2 datasets include neighbourhood target encoding and interaction features for improved predictive power.\n",
    "\n",
    "**Modeling strategy:**\n",
    "1. Baseline models with default parameters\n",
    "2. Log transformation experiments for linear models (to handle skewed price distribution)\n",
    "3. Hyperparameter tuning for top performers\n",
    "4. Final model selection and registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_section",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (38715, 29)\n",
      "Test set: (9777, 29)\n",
      "\n",
      "Feature count: 29\n",
      "\n",
      "Price range - Train: $10 to $795\n",
      "Price range - Test: $10 to $8000\n"
     ]
    }
   ],
   "source": [
    "# Load V2 preprocessed data from S3\n",
    "\n",
    "bucket_name = 'software-tools-ai'\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Load train data\n",
    "train_key = 'processed_data/train_processed_v2.csv'\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=train_key)\n",
    "train_df = pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "\n",
    "# Load test data\n",
    "test_key = 'processed_data/test_processed_v2.csv'\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=test_key)\n",
    "test_df = pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop('price', axis=1)\n",
    "y_train = train_df['price']\n",
    "\n",
    "X_test = test_df.drop('price', axis=1)\n",
    "y_test = test_df['price']\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nFeature count: {X_train.shape[1]}\")\n",
    "print(f\"\\nPrice range - Train: ${y_train.min():.0f} to ${y_train.max():.0f}\")\n",
    "print(f\"Price range - Test: ${y_test.min():.0f} to ${y_test.max():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mlflow_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow setup complete\n",
      "Tracking URI: http://35.183.177.64:5000\n",
      "Experiment: airbnb-price-prediction\n"
     ]
    }
   ],
   "source": [
    "# Connect to MLflow server on EC2\n",
    "mlflow.set_tracking_uri('http://35.183.177.64:5000')\n",
    "\n",
    "# Create/use experiment\n",
    "mlflow.set_experiment('airbnb-price-prediction')\n",
    "\n",
    "print(\"MLflow setup complete\")\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment: {mlflow.get_experiment_by_name('airbnb-price-prediction').name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "helper_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate models consistently\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Calculate regression metrics.\n",
    "    Evaluates on comparable price range (<$795) to avoid outlier distortion.\n",
    "    \"\"\"\n",
    "    # Full test set metrics\n",
    "    rmse_full = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae_full = mean_absolute_error(y_true, y_pred)\n",
    "    r2_full = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Comparable range metrics (price <= $795, which is ~99% of test data)\n",
    "    mask = y_true <= 795\n",
    "    rmse_comparable = np.sqrt(mean_squared_error(y_true[mask], y_pred[mask]))\n",
    "    mae_comparable = mean_absolute_error(y_true[mask], y_pred[mask])\n",
    "    r2_comparable = r2_score(y_true[mask], y_pred[mask])\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"  Full test set    - RMSE: ${rmse_full:.2f}, MAE: ${mae_full:.2f}, RÂ²: {r2_full:.3f}\")\n",
    "    print(f\"  Comparable range - RMSE: ${rmse_comparable:.2f}, MAE: ${mae_comparable:.2f}, RÂ²: {r2_comparable:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'rmse_full': rmse_full,\n",
    "        'mae_full': mae_full,\n",
    "        'r2_full': r2_full,\n",
    "        'rmse_comparable': rmse_comparable,\n",
    "        'mae_comparable': mae_comparable,\n",
    "        'r2_comparable': r2_comparable\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline_section",
   "metadata": {},
   "source": [
    "## Baseline Models\n",
    "\n",
    "Train baseline models with reasonable default parameters to establish performance benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "linear_baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Performance:\n",
      "  Full test set    - RMSE: $186.43, MAE: $62.83, RÂ²: 0.132\n",
      "  Comparable range - RMSE: $79.68, MAE: $49.97, RÂ²: 0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:39:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:39:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run linear_regression_v2 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/3c3e1600e15040a0bb728c5279c2bb05\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression - Baseline\n",
    "\n",
    "with mlflow.start_run(run_name=\"linear_regression_v2\"):\n",
    "    # Train\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = lr.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_model(y_test, predictions, \"Linear Regression\")\n",
    "    \n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "    mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "    mlflow.log_param(\"transform\", \"none\")\n",
    "    \n",
    "    mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "    mlflow.log_metric(\"mae_full\", metrics['mae_full'])\n",
    "    mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "    mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "    mlflow.log_metric(\"mae_comparable\", metrics['mae_comparable'])\n",
    "    mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "    \n",
    "    mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ridge_baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge (alpha=1.0) Performance:\n",
      "  Full test set    - RMSE: $186.43, MAE: $62.83, RÂ²: 0.132\n",
      "  Comparable range - RMSE: $79.68, MAE: $49.97, RÂ²: 0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:40:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:40:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run ridge_v2_alpha1 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/b36bdff6253a4ce388438e9274a06fea\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression - Baseline (alpha=1.0)\n",
    "\n",
    "with mlflow.start_run(run_name=\"ridge_v2_alpha1\"):\n",
    "    # Train\n",
    "    ridge = Ridge(alpha=1.0, random_state=42)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = ridge.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_model(y_test, predictions, \"Ridge (alpha=1.0)\")\n",
    "    \n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"Ridge\")\n",
    "    mlflow.log_param(\"alpha\", 1.0)\n",
    "    mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "    mlflow.log_param(\"transform\", \"none\")\n",
    "    \n",
    "    mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "    mlflow.log_metric(\"mae_full\", metrics['mae_full'])\n",
    "    mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "    mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "    mlflow.log_metric(\"mae_comparable\", metrics['mae_comparable'])\n",
    "    mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "    \n",
    "    mlflow.sklearn.log_model(ridge, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lasso_baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso (alpha=1.0) Performance:\n",
      "  Full test set    - RMSE: $186.73, MAE: $62.95, RÂ²: 0.129\n",
      "  Comparable range - RMSE: $80.01, MAE: $50.07, RÂ²: 0.391\n",
      "\n",
      "Features selected by Lasso: 9/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:40:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:40:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run lasso_v2_alpha1 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/f97ced4fcb1b49e69c761c463efd09fd\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression - Baseline (alpha=1.0)\n",
    "\n",
    "with mlflow.start_run(run_name=\"lasso_v2_alpha1\"):\n",
    "    # Train\n",
    "    lasso = Lasso(alpha=1.0, random_state=42, max_iter=10000)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = lasso.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_model(y_test, predictions, \"Lasso (alpha=1.0)\")\n",
    "    \n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"Lasso\")\n",
    "    mlflow.log_param(\"alpha\", 1.0)\n",
    "    mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "    mlflow.log_param(\"transform\", \"none\")\n",
    "    \n",
    "    # Check feature selection\n",
    "    n_features_used = np.sum(lasso.coef_ != 0)\n",
    "    mlflow.log_metric(\"n_features_selected\", n_features_used)\n",
    "    print(f\"\\nFeatures selected by Lasso: {n_features_used}/{len(lasso.coef_)}\")\n",
    "    \n",
    "    mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "    mlflow.log_metric(\"mae_full\", metrics['mae_full'])\n",
    "    mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "    mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "    mlflow.log_metric(\"mae_comparable\", metrics['mae_comparable'])\n",
    "    mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "    \n",
    "    mlflow.sklearn.log_model(lasso, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "rf_baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Performance:\n",
      "  Full test set    - RMSE: $180.91, MAE: $57.54, RÂ²: 0.183\n",
      "  Comparable range - RMSE: $73.89, MAE: $45.00, RÂ²: 0.480\n",
      "ðŸƒ View run random_forest_v2_baseline at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/9a6ba9f1cdb94fcabe21ded940abe461\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - Baseline\n",
    "\n",
    "with mlflow.start_run(run_name=\"random_forest_v2_baseline\"):\n",
    "    # Train\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = rf.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_model(y_test, predictions, \"Random Forest\")\n",
    "    \n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 20)\n",
    "    mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "    \n",
    "    mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "    mlflow.log_metric(\"mae_full\", metrics['mae_full'])\n",
    "    mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "    mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "    mlflow.log_metric(\"mae_comparable\", metrics['mae_comparable'])\n",
    "    mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "    \n",
    "    # mlflow.sklearn.log_model(rf, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "xgb_baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Performance:\n",
      "  Full test set    - RMSE: $180.39, MAE: $56.88, RÂ²: 0.187\n",
      "  Comparable range - RMSE: $72.85, MAE: $44.33, RÂ²: 0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:40:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:40:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run xgboost_v2_baseline at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/f71a6196735e49b395446a2af93ae98f\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# XGBoost - Baseline\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgboost_v2_baseline\"):\n",
    "    # Train\n",
    "    xgb = XGBRegressor(n_estimators=100, max_depth=7, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = xgb.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_model(y_test, predictions, \"XGBoost\")\n",
    "    \n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 7)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "    mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "    \n",
    "    mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "    mlflow.log_metric(\"mae_full\", metrics['mae_full'])\n",
    "    mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "    mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "    mlflow.log_metric(\"mae_comparable\", metrics['mae_comparable'])\n",
    "    mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "    \n",
    "    mlflow.sklearn.log_model(xgb, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline_summary",
   "metadata": {},
   "source": [
    "### Baseline Results Summary\n",
    "\n",
    "After running all baseline models, review the MLflow UI to identify top performers before proceeding to log transformation experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "log_transform_section",
   "metadata": {},
   "source": [
    "## Log Transformation Experiments\n",
    "\n",
    "Linear models assume a linear relationship between features and target. However, Airbnb prices are right-skewed (many cheap listings, few expensive ones). Log transformation compresses this distribution, potentially improving linear model performance.\n",
    "\n",
    "**Why log transform helps:**\n",
    "- Reduces impact of outliers without removing them\n",
    "- Makes relationship more linear\n",
    "- Stabilizes variance (homoscedasticity)\n",
    "\n",
    "**Note:** Tree-based models (RF, XGBoost) don't need this transformation as they're already robust to skewed distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "log_transform_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original price range: $10.00 to $795.00\n",
      "Log-transformed range: 2.40 to 6.68\n",
      "\n",
      "Log transformation compresses the scale and reduces outlier impact\n"
     ]
    }
   ],
   "source": [
    "# Transform target variable to log scale\n",
    "\n",
    "# Using log1p = log(1 + x) to handle edge cases\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "print(f\"Original price range: ${y_train.min():.2f} to ${y_train.max():.2f}\")\n",
    "print(f\"Log-transformed range: {y_train_log.min():.2f} to {y_train_log.max():.2f}\")\n",
    "print(f\"\\nLog transformation compresses the scale and reduces outlier impact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "linear_log",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression + Log Performance:\n",
      "  Full test set    - RMSE: $188.16, MAE: $59.60, RÂ²: 0.116\n",
      "  Comparable range - RMSE: $80.90, MAE: $46.54, RÂ²: 0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:40:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:40:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run linear_v2_log_transform at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/7d52ea2ed6cb402f897aadf42165c972\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression + Log Transform\n",
    "\n",
    "with mlflow.start_run(run_name=\"linear_v2_log_transform\"):\n",
    "    # Train on log scale\n",
    "    lr_log = LinearRegression()\n",
    "    lr_log.fit(X_train, y_train_log)\n",
    "    \n",
    "    # Predict on log scale\n",
    "    predictions_log = lr_log.predict(X_test)\n",
    "    \n",
    "    # Convert back to original scale\n",
    "    predictions = np.expm1(predictions_log)  # expm1 = exp(x) - 1\n",
    "    \n",
    "    # Evaluate on original scale\n",
    "    metrics = evaluate_model(y_test, predictions, \"Linear Regression + Log\")\n",
    "    \n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "    mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "    mlflow.log_param(\"transform\", \"log\")\n",
    "    \n",
    "    mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "    mlflow.log_metric(\"mae_full\", metrics['mae_full'])\n",
    "    mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "    mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "    mlflow.log_metric(\"mae_comparable\", metrics['mae_comparable'])\n",
    "    mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "    \n",
    "    mlflow.sklearn.log_model(lr_log, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ridge_log",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge + Log (alpha=1.0) Performance:\n",
      "  Full test set    - RMSE: $188.16, MAE: $59.60, RÂ²: 0.116\n",
      "  Comparable range - RMSE: $80.90, MAE: $46.54, RÂ²: 0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:41:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:41:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run ridge_v2_log_alpha1 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/6df8747490544f4e99980cc7dcc9c7e0\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# Ridge + Log Transform\n",
    "\n",
    "with mlflow.start_run(run_name=\"ridge_v2_log_alpha1\"):\n",
    "    # Train on log scale\n",
    "    ridge_log = Ridge(alpha=1.0, random_state=42)\n",
    "    ridge_log.fit(X_train, y_train_log)\n",
    "    \n",
    "    # Predict and convert back\n",
    "    predictions_log = ridge_log.predict(X_test)\n",
    "    predictions = np.expm1(predictions_log)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_model(y_test, predictions, \"Ridge + Log (alpha=1.0)\")\n",
    "    \n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"Ridge\")\n",
    "    mlflow.log_param(\"alpha\", 1.0)\n",
    "    mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "    mlflow.log_param(\"transform\", \"log\")\n",
    "    \n",
    "    mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "    mlflow.log_metric(\"mae_full\", metrics['mae_full'])\n",
    "    mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "    mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "    mlflow.log_metric(\"mae_comparable\", metrics['mae_comparable'])\n",
    "    mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "    \n",
    "    mlflow.sklearn.log_model(ridge_log, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lasso_log",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso + Log (alpha=1.0) Performance:\n",
      "  Full test set    - RMSE: $204.17, MAE: $82.76, RÂ²: -0.041\n",
      "  Comparable range - RMSE: $105.91, MAE: $69.25, RÂ²: -0.068\n",
      "\n",
      "Features selected by Lasso: 0/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:41:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:41:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run lasso_v2_log_alpha1 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/ed05058c1fa1485f8a1d2c474b4a8e4e\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# Lasso + Log Transform\n",
    "\n",
    "with mlflow.start_run(run_name=\"lasso_v2_log_alpha1\"):\n",
    "    # Train on log scale\n",
    "    lasso_log = Lasso(alpha=1.0, random_state=42, max_iter=10000)\n",
    "    lasso_log.fit(X_train, y_train_log)\n",
    "    \n",
    "    # Predict and convert back\n",
    "    predictions_log = lasso_log.predict(X_test)\n",
    "    predictions = np.expm1(predictions_log)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_model(y_test, predictions, \"Lasso + Log (alpha=1.0)\")\n",
    "    \n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"Lasso\")\n",
    "    mlflow.log_param(\"alpha\", 1.0)\n",
    "    mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "    mlflow.log_param(\"transform\", \"log\")\n",
    "    \n",
    "    n_features_used = np.sum(lasso_log.coef_ != 0)\n",
    "    mlflow.log_metric(\"n_features_selected\", n_features_used)\n",
    "    print(f\"\\nFeatures selected by Lasso: {n_features_used}/{len(lasso_log.coef_)}\")\n",
    "    \n",
    "    mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "    mlflow.log_metric(\"mae_full\", metrics['mae_full'])\n",
    "    mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "    mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "    mlflow.log_metric(\"mae_comparable\", metrics['mae_comparable'])\n",
    "    mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "    \n",
    "    mlflow.sklearn.log_model(lasso_log, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tuning_section",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Based on baseline results, tune hyperparameters for the top-performing models. This section focuses on the models that showed the most promise in initial experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ridge_tuning_header",
   "metadata": {},
   "source": [
    "### Ridge/Lasso Alpha Tuning\n",
    "\n",
    "Alpha controls regularization strength. Test different values to find optimal balance between bias and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ridge_tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge (alpha=0.1) Performance:\n",
      "  Full test set    - RMSE: $186.43, MAE: $62.83, RÂ²: 0.132\n",
      "  Comparable range - RMSE: $79.68, MAE: $49.97, RÂ²: 0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:41:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:41:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run ridge_v2_alpha0.1 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/eeac96b7833f4087a48297131ff788c7\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n",
      "\n",
      "Ridge (alpha=10.0) Performance:\n",
      "  Full test set    - RMSE: $186.43, MAE: $62.82, RÂ²: 0.132\n",
      "  Comparable range - RMSE: $79.67, MAE: $49.96, RÂ²: 0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:41:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:41:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run ridge_v2_alpha10.0 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/294c9f2e8db743f4ac1af9d685e1f4c9\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n",
      "\n",
      "Ridge (alpha=100.0) Performance:\n",
      "  Full test set    - RMSE: $186.45, MAE: $62.79, RÂ²: 0.132\n",
      "  Comparable range - RMSE: $79.67, MAE: $49.93, RÂ²: 0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:41:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:41:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run ridge_v2_alpha100.0 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/4258b0334e95460eb4816232b6ae37d4\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# Ridge alpha tuning\n",
    "\n",
    "alphas = [0.1, 10.0, 100.0]\n",
    "\n",
    "for alpha in alphas:\n",
    "    with mlflow.start_run(run_name=f\"ridge_v2_alpha{alpha}\"):\n",
    "        # Train\n",
    "        ridge = Ridge(alpha=alpha, random_state=42)\n",
    "        ridge.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        predictions = ridge.predict(X_test)\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate_model(y_test, predictions, f\"Ridge (alpha={alpha})\")\n",
    "        \n",
    "        # Log to MLflow\n",
    "        mlflow.log_param(\"model_type\", \"Ridge\")\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "        mlflow.log_param(\"transform\", \"none\")\n",
    "        \n",
    "        mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "        mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "        mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "        mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "        \n",
    "        mlflow.sklearn.log_model(ridge, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rf_tuning_header",
   "metadata": {},
   "source": [
    "### Random Forest Tuning\n",
    "\n",
    "Tune n_estimators, max_depth, and min_samples_split for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rf_tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2} Performance:\n",
      "  Full test set    - RMSE: $180.76, MAE: $57.41, RÂ²: 0.184\n",
      "  Comparable range - RMSE: $73.75, MAE: $44.88, RÂ²: 0.482\n",
      "ðŸƒ View run rf_v2_n200_d20_s2 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/81f212bb13e2491faa299928d63b9b23\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n",
      "\n",
      "RF {'n_estimators': 100, 'max_depth': 25, 'min_samples_split': 2} Performance:\n",
      "  Full test set    - RMSE: $180.74, MAE: $57.73, RÂ²: 0.184\n",
      "  Comparable range - RMSE: $74.08, MAE: $45.22, RÂ²: 0.478\n",
      "ðŸƒ View run rf_v2_n100_d25_s2 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/bc86a04d05bb42b8b69d15f3ec8eca61\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n",
      "\n",
      "RF {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 5} Performance:\n",
      "  Full test set    - RMSE: $180.68, MAE: $57.49, RÂ²: 0.185\n",
      "  Comparable range - RMSE: $73.76, MAE: $44.96, RÂ²: 0.482\n",
      "ðŸƒ View run rf_v2_n200_d25_s5 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/dc9c0feb27a24f968d037f386ee591ed\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# Random Forest tuning\n",
    "\n",
    "rf_configs = [\n",
    "    {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 2},\n",
    "    {'n_estimators': 100, 'max_depth': 25, 'min_samples_split': 2},\n",
    "    {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 5},\n",
    "]\n",
    "\n",
    "for config in rf_configs:\n",
    "    run_name = f\"rf_v2_n{config['n_estimators']}_d{config['max_depth']}_s{config['min_samples_split']}\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Train\n",
    "        rf = RandomForestRegressor(\n",
    "            n_estimators=config['n_estimators'],\n",
    "            max_depth=config['max_depth'],\n",
    "            min_samples_split=config['min_samples_split'],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        predictions = rf.predict(X_test)\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate_model(y_test, predictions, f\"RF {config}\")\n",
    "        \n",
    "        # Log to MLflow\n",
    "        mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "        mlflow.log_param(\"n_estimators\", config['n_estimators'])\n",
    "        mlflow.log_param(\"max_depth\", config['max_depth'])\n",
    "        mlflow.log_param(\"min_samples_split\", config['min_samples_split'])\n",
    "        mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "        \n",
    "        mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "        mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "        mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "        mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "        \n",
    "        # mlflow.sklearn.log_model(rf, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xgb_tuning_header",
   "metadata": {},
   "source": [
    "### XGBoost Tuning\n",
    "\n",
    "Tune learning_rate, max_depth, and n_estimators for gradient boosting optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "xgb_tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGB {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1} Performance:\n",
      "  Full test set    - RMSE: $180.01, MAE: $56.79, RÂ²: 0.191\n",
      "  Comparable range - RMSE: $72.79, MAE: $44.27, RÂ²: 0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:41:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:41:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run xgb_v2_n200_d7_lr0.1 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/40fd11a5e85a4013afe811d02140c751\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n",
      "\n",
      "XGB {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.1} Performance:\n",
      "  Full test set    - RMSE: $180.47, MAE: $56.79, RÂ²: 0.186\n",
      "  Comparable range - RMSE: $72.86, MAE: $44.21, RÂ²: 0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:42:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:42:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run xgb_v2_n100_d9_lr0.1 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/ddc8175785564ea39199bcc2ef146577\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n",
      "\n",
      "XGB {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05} Performance:\n",
      "  Full test set    - RMSE: $181.59, MAE: $57.58, RÂ²: 0.176\n",
      "  Comparable range - RMSE: $73.50, MAE: $44.95, RÂ²: 0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 09:42:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 09:42:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run xgb_v2_n200_d5_lr0.05 at: http://35.183.177.64:5000/#/experiments/279774441150129579/runs/5b78a65c9ab04a13bddfdf60beaea1cd\n",
      "ðŸ§ª View experiment at: http://35.183.177.64:5000/#/experiments/279774441150129579\n"
     ]
    }
   ],
   "source": [
    "# XGBoost tuning\n",
    "\n",
    "xgb_configs = [\n",
    "    {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1},\n",
    "    {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.1},\n",
    "    {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05},\n",
    "]\n",
    "\n",
    "for config in xgb_configs:\n",
    "    run_name = f\"xgb_v2_n{config['n_estimators']}_d{config['max_depth']}_lr{config['learning_rate']}\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Train\n",
    "        xgb = XGBRegressor(\n",
    "            n_estimators=config['n_estimators'],\n",
    "            max_depth=config['max_depth'],\n",
    "            learning_rate=config['learning_rate'],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        xgb.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        predictions = xgb.predict(X_test)\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate_model(y_test, predictions, f\"XGB {config}\")\n",
    "        \n",
    "        # Log to MLflow\n",
    "        mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "        mlflow.log_param(\"n_estimators\", config['n_estimators'])\n",
    "        mlflow.log_param(\"max_depth\", config['max_depth'])\n",
    "        mlflow.log_param(\"learning_rate\", config['learning_rate'])\n",
    "        mlflow.log_param(\"dataset_version\", \"v2\")\n",
    "        \n",
    "        mlflow.log_metric(\"rmse_comparable\", metrics['rmse_comparable'])\n",
    "        mlflow.log_metric(\"r2_comparable\", metrics['r2_comparable'])\n",
    "        mlflow.log_metric(\"rmse_full\", metrics['rmse_full'])\n",
    "        mlflow.log_metric(\"r2_full\", metrics['r2_full'])\n",
    "        \n",
    "        mlflow.sklearn.log_model(xgb, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_selection",
   "metadata": {},
   "source": [
    "## Model Selection and Registration\n",
    "\n",
    "Review all experiments in MLflow UI, select the best model based on r2_comparable metric, and register it for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mlflow_link",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access MLflow UI to review all experiments\n",
    "print(\"Review all experiments at: http://35.183.177.64:5000\")\n",
    "print(\"\\nSort runs by 'r2_comparable' metric (descending) to find best model\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Identify best performing model\")\n",
    "print(\"2. Register model in MLflow Model Registry\")\n",
    "print(\"3. Take screenshots for documentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "**To be completed after reviewing MLflow results:**\n",
    "\n",
    "**Best model:**\n",
    "- Model type: [TBD]\n",
    "- RMSE (comparable): [TBD]\n",
    "- RÂ² (comparable): [TBD]\n",
    "\n",
    "**Key insights:**\n",
    "- Impact of neighbourhood target encoding on model performance\n",
    "- Effectiveness of log transformation for linear models\n",
    "- Comparison between linear and tree-based approaches\n",
    "- Dataset limitations (RÂ² ceiling around 0.50 due to missing features like bedrooms, bathrooms, amenities)\n",
    "\n",
    "**Next steps:**\n",
    "- Register best model in MLflow\n",
    "- Document findings in README\n",
    "- Prepare final presentation materials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnbpredictors3",
   "language": "python",
   "name": "airbnbpredictors3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
